{
  "openapi": "3.1.0",
  "info": {
    "title": "ðŸ‘‹Jan Server API",
    "description": "OpenAI-compatible API for Jan Server powered by vLLM. High-performance, scalable inference service with automatic batching and optimized memory management.",
    "version": "0.3.14",
    "contact": {
      "name": "Jan Server Support",
      "url": "https://jan.ai/support",
      "email": "support@jan.ai"
    },
    "license": {
      "name": "Apache 2.0",
      "url": "https://github.com/menloresearch/jan/blob/main/LICENSE"
    },
    "x-logo": {
      "url": "https://jan.ai/logo.png",
      "altText": "ðŸ‘‹Jan Server API"
    }
  },
  "servers": [
    {
      "url": "https://api.jan.ai/v1",
      "description": "Jan Server API (Production)"
    },
    {
      "url": "https://staging-api.jan.ai/v1",
      "description": "Jan Server API (Staging)"
    },
    {
      "url": "http://localhost:8000/v1",
      "description": "Jan Server (Local Development)"
    },
    {
      "url": "http://jan-server.local:8000/v1",
      "description": "Jan Server (Minikube)"
    }
  ],
  "tags": [
    {
      "name": "Models",
      "description": "List and describe available models"
    },
    {
      "name": "Chat",
      "description": "Chat completion endpoints for conversational AI"
    },
    {
      "name": "Completions",
      "description": "Text completion endpoints"
    },
    {
      "name": "Embeddings",
      "description": "Generate embeddings for text"
    },
    {
      "name": "Usage",
      "description": "Monitor API usage and quotas"
    }
  ],
  "paths": {
    "/v1/completions": {
      "post": {
        "tags": [
          "Completions"
        ],
        "summary": "Create completion",
        "description": "Creates a completion for the provided prompt and parameters. This endpoint is compatible with OpenAI's completions API.",
        "operationId": "create_completion",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/CreateCompletionRequest"
              },
              "examples": {
                "text-completion": {
                  "summary": "Text Completion Example",
                  "description": "Complete text using llama-3.1-8b-instruct",
                  "value": {
                    "model": "llama-3.1-8b-instruct",
                    "prompt": "Once upon a time,",
                    "max_tokens": 50,
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "stream": false
                  }
                }
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/CreateCompletionResponse"
                }
              }
            }
          },
          "202": {
            "description": "Accepted - Request is being processed",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/CreateCompletionResponse"
                }
              },
              "text/event-stream": {
                "schema": {
                  "type": "string",
                  "format": "binary",
                  "description": "Server-sent events stream for streaming responses"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ValidationError"
                }
              }
            }
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ]
      }
    },
    "/v1/chat/completions": {
      "post": {
        "tags": [
          "Chat"
        ],
        "summary": "Create chat completion",
        "description": "Creates a model response for the given chat conversation. This endpoint is compatible with OpenAI's chat completions API.",
        "operationId": "create_chat_completion",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/CreateChatCompletionRequest"
              },
              "examples": {
                "simple-chat": {
                  "summary": "Simple Chat Example",
                  "description": "Chat completion using llama-3.1-8b-instruct",
                  "value": {
                    "model": "llama-3.1-8b-instruct",
                    "messages": [
                      {
                        "role": "user",
                        "content": "What is the capital of France?"
                      }
                    ],
                    "max_tokens": 100,
                    "temperature": 0.7,
                    "stream": false
                  }
                }
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/CreateChatCompletionResponse"
                }
              },
              "text/event-stream": {
                "schema": {
                  "type": "string",
                  "format": "binary",
                  "description": "Server-sent events stream for streaming responses"
                }
              }
            }
          },
          "202": {
            "description": "Accepted - Request is being processed",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/CreateChatCompletionResponse"
                }
              },
              "text/event-stream": {
                "schema": {
                  "type": "string",
                  "format": "binary",
                  "description": "Server-sent events stream for streaming responses"
                }
              }
            }
          },
          "422": {
            "description": "Validation Error",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ValidationError"
                }
              }
            }
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ]
      }
    },
    "/v1/models": {
      "get": {
        "tags": [
          "Models"
        ],
        "summary": "List available models",
        "description": "Lists the currently available models and provides basic information about each one such as the owner and availability.",
        "operationId": "list_models",
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/ModelList"
                },
                "example": {
                  "object": "list",
                  "data": [
                    {
                      "id": "gemma-2-2b-it-Q8_0",
                      "object": "model",
                      "created": 1686935002,
                      "owned_by": "jan"
                    },
                    {
                      "id": "llama-3.1-8b-instruct-Q4_K_M",
                      "object": "model",
                      "created": 1686935002,
                      "owned_by": "jan"
                    },
                    {
                      "id": "mistral-7b-instruct-v0.3-Q4_K_M",
                      "object": "model",
                      "created": 1686935002,
                      "owned_by": "jan"
                    },
                    {
                      "id": "phi-3-mini-4k-instruct-Q4_K_M",
                      "object": "model",
                      "created": 1686935002,
                      "owned_by": "jan"
                    }
                  ]
                }
              }
            }
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ]
      }
    },
    "/extras/tokenize": {
      "post": {
        "tags": [
          "Extras"
        ],
        "summary": "Tokenize text",
        "description": "Convert text input into tokens using the model's tokenizer.",
        "operationId": "tokenize",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/TokenizeRequest"
              },
              "example": {
                "input": "Hello, world!",
                "model": "gemma-2-2b-it-Q8_0"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/TokenizeResponse"
                },
                "example": {
                  "tokens": [
                    15339,
                    11,
                    1917,
                    0
                  ]
                }
              }
            }
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ]
      }
    },
    "/extras/tokenize/count": {
      "post": {
        "tags": [
          "Extras"
        ],
        "summary": "Count tokens",
        "description": "Count the number of tokens in the provided text.",
        "operationId": "count_tokens",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/TokenizeRequest"
              },
              "example": {
                "input": "How many tokens does this text have?",
                "model": "gemma-2-2b-it-Q8_0"
              }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful Response",
            "content": {
              "application/json": {
                "schema": {
                  "$ref": "#/components/schemas/TokenCountResponse"
                },
                "example": {
                  "count": 8
                }
              }
            }
          }
        },
        "security": [
          {
            "bearerAuth": []
          }
        ]
      }
    }
  },
  "components": {
    "schemas": {
      "TokenizeRequest": {
        "type": "object",
        "properties": {
          "input": {
            "type": "string",
            "description": "The text to tokenize"
          },
          "model": {
            "type": "string",
            "description": "The model to use for tokenization",
            "enum": [
              "gemma-2-2b-it-Q8_0",
              "llama-3.1-8b-instruct-Q4_K_M",
              "mistral-7b-instruct-v0.3-Q4_K_M",
              "phi-3-mini-4k-instruct-Q4_K_M"
            ]
          }
        },
        "required": [
          "input"
        ]
      },
      "TokenizeResponse": {
        "type": "object",
        "properties": {
          "tokens": {
            "type": "array",
            "items": {
              "type": "integer"
            },
            "description": "Array of token IDs"
          }
        },
        "required": [
          "tokens"
        ]
      },
      "TokenCountResponse": {
        "type": "object",
        "properties": {
          "count": {
            "type": "integer",
            "description": "Number of tokens"
          }
        },
        "required": [
          "count"
        ]
      }
    },
    "securitySchemes": {
      "bearerAuth": {
        "type": "http",
        "scheme": "bearer",
        "bearerFormat": "JWT",
        "description": "Enter your Jan Server API key. Configure authentication in your server settings."
      }
    }
  },
  "x-jan-local-features": {
    "engine": "llama.cpp",
    "features": [
      "GGUF model support",
      "CPU and GPU acceleration",
      "Quantized model support (Q4, Q5, Q8)",
      "Metal acceleration on macOS",
      "CUDA support on NVIDIA GPUs",
      "ROCm support on AMD GPUs",
      "AVX/AVX2/AVX512 optimizations",
      "Memory-mapped model loading"
    ],
    "privacy": {
      "local_processing": true,
      "no_telemetry": true,
      "offline_capable": true
    },
    "model_formats": [
      "GGUF",
      "GGML"
    ],
    "default_settings": {
      "context_length": 4096,
      "batch_size": 512,
      "threads": "auto"
    }
  },
  "security": [
    {
      "bearerAuth": []
    }
  ],
  "x-jan-server-features": {
    "vllm": {
      "version": "0.5.0",
      "features": [
        "PagedAttention for efficient memory management",
        "Continuous batching for high throughput",
        "Tensor parallelism for multi-GPU serving",
        "Quantization support (AWQ, GPTQ, SqueezeLLM)",
        "Speculative decoding",
        "LoRA adapter support"
      ]
    },
    "scaling": {
      "auto_scaling": true,
      "min_replicas": 1,
      "max_replicas": 100,
      "target_qps": 100
    },
    "limits": {
      "max_tokens_per_request": 32768,
      "max_batch_size": 256,
      "timeout_seconds": 300
    }
  }
}